{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01fa68b-1e71-4a5d-a68a-77b4d6e810f7",
   "metadata": {},
   "source": [
    "# Pydantic validation framework for the EMO BON observatory and other metadata log sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb619d-5b92-4bee-b1a5-b3f0cb364f70",
   "metadata": {},
   "source": [
    "- **pydantic** Data validation using Python type hints.\n",
    "    - [pypi](https://pypi.org/project/pydantic/)\n",
    "    - [Documentation](https://docs.pydantic.dev/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bca054-8458-4137-ae94-b960bbe0ad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD is /srv/scratch/emo-bon-data-validation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Weird stuff from JupyterHub after I moved modules and notebooks around:\n",
    "# For some reasong CWD is /src/scratch even though this notebook is in /srv/scratch/emo-bon-validation\n",
    "# The terminal also show us to be in /srv/scratch/emo-bon-validation\n",
    "# So...\n",
    "if os.getcwd() == \"/srv/scratch\":\n",
    "    os.chdir(\"./emo-bon-data-validation\")\n",
    "print(f\"CWD is {os.getcwd()}\")\n",
    "\n",
    "import importlib\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0a524-4ac9-4840-ba77-b031296619fa",
   "metadata": {},
   "source": [
    "##### Init the directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d4afacf-09d3-47dc-80cc-e00d3e9232c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    #Init dirs and paths, write csv files\n",
    "    # Init the validation classes dir if needed\n",
    "    # Note that __init__.py will need be edited manually to import the validators\n",
    "    # e.g from .observatories import Model as observatoriesModel\n",
    "    validation_classes_path = \"./validation_classes\"\n",
    "    if True:\n",
    "        if not os.path.exists(validation_classes_path):\n",
    "            os.mkdir(validation_classes_path)\n",
    "            Path(os.path.join(validation_classes_path, \"__init__.py\")).touch()\n",
    "            os.mkdir(raw_files_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e601478-27ea-404a-8371-1405051ccf22",
   "metadata": {},
   "source": [
    "## Governance data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e34558-fb7c-4000-8e8b-24ad71df7eab",
   "metadata": {},
   "source": [
    "#### Read each of the governance CSV files into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154ba717-c9a9-43a0-b34e-8b7461952135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 9 columns):\n",
      " #   Column                               Non-Null Count  Dtype \n",
      "---  ------                               --------------  ----- \n",
      " 0   EMBRC Node                           18 non-null     object\n",
      " 1   EMBRC Site                           18 non-null     object\n",
      " 2   EMOBON_observatory_id                18 non-null     object\n",
      " 3   Water Column                         17 non-null     object\n",
      " 4   Soft sediment                        7 non-null      object\n",
      " 5   data_quality_control_threshold_date  18 non-null     object\n",
      " 6   data_quality_control_assignee        18 non-null     object\n",
      " 7   rocrate_profile_uri                  18 non-null     object\n",
      " 8   autogenerate                         18 non-null     int64 \n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 1.4+ KB\n",
      "This is info() for None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 22 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   country_code                      19 non-null     object \n",
      " 1   country                           19 non-null     object \n",
      " 2   EMOBON_observatory_name           19 non-null     object \n",
      " 3   EMOBON_observatory_id             19 non-null     object \n",
      " 4   startdate                         19 non-null     object \n",
      " 5   enddate                           2 non-null      object \n",
      " 6   Water_Column                      19 non-null     object \n",
      " 7   Soft_Substrates                   19 non-null     object \n",
      " 8   Hard_Substrates                   19 non-null     object \n",
      " 9   water_site_latitude               18 non-null     float64\n",
      " 10  water_site_longitude              18 non-null     float64\n",
      " 11  sediment_site_latitude            9 non-null      float64\n",
      " 12  sediment_site_longtitude          9 non-null      float64\n",
      " 13  hard_substrates_site1_longitude   9 non-null      object \n",
      " 14  hard_substrates_site1_latitude    9 non-null      object \n",
      " 15  hard_substrates_site2_longtitude  3 non-null      float64\n",
      " 16  hard_substrates_site2_latitude    3 non-null      float64\n",
      " 17  contect person                    19 non-null     object \n",
      " 18  contact person email              19 non-null     object \n",
      " 19  ENA_accession_number_umbrella     19 non-null     object \n",
      " 20  ENA_accession_number_project      19 non-null     object \n",
      " 21  EMOBON_core                       19 non-null     object \n",
      "dtypes: float64(6), object(16)\n",
      "memory usage: 3.4+ KB\n",
      "This is info() for None\n"
     ]
    }
   ],
   "source": [
    "github_path = \"https://raw.githubusercontent.com/emo-bon/governance-data/main/\"\n",
    "file_names = [\n",
    "        \"logsheets.csv\",              # contain the URLs of the googlesheets that are the logsheets\n",
    "        \"observatories.csv\"           # contain information about each observatory\n",
    "        #\"organisations.csv\",         # contain information about the organisations in EMO BON\n",
    "        #\"planned_events.csv\"         # contains information about planned EMO BON events (this file is only used by humans, not by any actions) - DONT CARE\n",
    "        #\"ro-crate-metadata.json\"     # IGNORE\n",
    "        ]\n",
    "dfs = {}\n",
    "for f in file_names:\n",
    "    df = pd.read_csv(os.path.join(github_path, f))\n",
    "    print(f\"This is info() for {df.info()}\")\n",
    "    dfs[f] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484615f-cab2-48a2-8ca7-999bab0051e3",
   "metadata": {},
   "source": [
    "#### Validate Governance tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8dc50e0-2d84-4508-8d82-67b90397c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation_classes import observatoriesModel, logsheetsModel\n",
    "validator_class_paths = {\"logsheets.csv\": logsheetsModel, \"observatories.csv\": observatoriesModel}\n",
    "validation_classes_path = \"./validation_classes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa819fa6-c492-481f-bc81-218057699342",
   "metadata": {},
   "source": [
    "##### Observatories table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3dfa6-8d4c-4749-b9d1-bc00834e1a3b",
   "metadata": {},
   "source": [
    "The observatories validator mostly changes the column names to make them consistent (and spelled correctly), removes blank strings (\"   \") from cells, and reformats the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa2840b-9b25-4155-bd43-34cea9c81de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"observatories.csv\"\n",
    "data = dfs[file_name] # dfs is dict of pandas df's\n",
    "validator = validator_class_paths[file_name]\n",
    "data_records = data.to_dict(orient=\"records\")\n",
    "validated_rows = [validator(**row).model_dump() for row in data_records]\n",
    "\n",
    "ndf = pd.DataFrame.from_records(validated_rows, index=\"observatory_id\")\n",
    "ndf.to_csv(os.path.join(\"governance\", \"observatories_validated.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef5ade-e3f4-4742-b1ba-41233e93e80c",
   "metadata": {},
   "source": [
    "##### Logsheets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b9e1b9e-8a05-4bf2-aceb-55c5c740e77d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cdir = os.getcwd()\n",
    "file_name = \"logsheets.csv\"\n",
    "data = dfs[file_name] # dfs is dict of pandas df's\n",
    "validator = validator_class_paths[file_name]\n",
    "data_records = data.to_dict(orient=\"records\")\n",
    "validated_rows = [validator(**row).model_dump() for row in data_records]\n",
    "        \n",
    "ndf = pd.DataFrame.from_records(validated_rows, index=\"observatory_id\")\n",
    "ndf.to_csv(os.path.join(\"governance\", \"logsheets_validated.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc138c-c96f-4349-843c-ad02276b5f43",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Logsheets from water column and soft sediments sampling and \"measured\" tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0343f-e36b-4685-ac17-e90a9e53f12d",
   "metadata": {},
   "source": [
    "##### Pulls from the raw Google Sheets does a \"lax\" validation where we correct/coerce everything to a consistent type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b41f0d-7d88-46e4-9789-442036904749",
   "metadata": {},
   "source": [
    "### !!! A note about Pandas and integer fields with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45ba77-48d0-422c-940c-a0c1b396f16a",
   "metadata": {},
   "source": [
    "Pandas will read a raw CSV file and try to determine the type while doing so. If it finds an integer column with missing values they will be NaN's, which of course are floats. Consequently, the default action here is to read the column as a floats by coercing the integer values to float to match the NaNs - this is rarely what you want.\n",
    "\n",
    "However, Pandas does have a [nullable integer type](https://pandas.pydata.org/docs/user_guide/integer_na.html) - `pandas.Int64Dtype()` or it's string alias `\"Int64\"`. You can force Pandas to use this type when reading the CSV file using `pandas.read_csv('file.csv', dtype={\"<int field with missing values>\": \"Int64\"})` the NaN's will be changed to [pandas.NA types](https://pandas.pydata.org/docs/reference/api/pandas.NA.html#pandas.NA).\n",
    "\n",
    "For clarity: this is NOT what happens below: we let the validators deal with it, which coerce the now floats back into ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95e6614-c9ff-470d-8363-8f37a08d34ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "observatory_ids=['BPNS', 'EMT21', 'PiEGetxo', 'VB', 'OOB', 'ROSKOGO', 'HCMR-1', 'IUIEilat1', 'NRMCB', 'AAOT', 'Bergen', 'ESC68N', 'RFormosa', 'OSD74', 'MBAL4', 'STHVN', 'UMF', 'LMO', 'Plenzia']\n",
      "\n",
      "\n",
      "Processing observatory_id='ESC68N' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/11_Eu0W1-sDiuzKx1cIl6YuxjRHmWezN6u9v3Ly8JZ3A/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 114 records leaving 150.\n",
      "Written ./logsheets/ESC68N_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='Bergen' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1HuXHiUJICZrmCrJ4EZDyU5aSCMzDAc1cy_tne5YVPTg/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/Bergen_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='MBAL4' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1xfrqraPa0auQ1O-C9RUo68RhxrPCDWkVMCAUbj79AZI/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/MBAL4_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='BPNS' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1mEi4Bd2YR63WD0j54FQ6QkzcUw_As9Wilue9kaXO2DE/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/BPNS_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='ROSKOGO' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1BCu2pbuIS4f-yrw5Kw4uzfO9v6ryZJBtSF5WBLWG_-E/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/ROSKOGO_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='VB' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1kSlTcNfXaCQv7fIKVbBnt5PmRW3_H7Trryh4FJHyLkE/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 32 records leaving 824.\n",
      "Written ./logsheets/VB_water_column_sampling_validated.csv\n",
      "Observatory OOB lacks valid sheet URL for water_column\n",
      "\n",
      "\n",
      "Processing observatory_id='EMT21' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1RutVpduwL1mEed5jC2zLbs0DgkzAwZdsJ27fg3kb0Yg/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/EMT21_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='PiEGetxo' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1KGcishLP5eAn6ZCnixn5wZIez1Y9MgmYoch2s7aefKM/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/PiEGetxo_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='RFormosa' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/15f_yqrhvOr1MW-SHuv0JiKf0HRDy81uGZapJANxL54k/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/RFormosa_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='OSD74' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1VATpzmhwmk8sYkhEjCbDUZHRiYuNGpSRefhXthZRbfQ/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 28 records leaving 170.\n",
      "Written ./logsheets/OSD74_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='AAOT' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1hvLkBwiKTGTJDx19m_8e7qJ2lm9bwLLeVztMpxTLqnk/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 188 records leaving 400.\n",
      "Written ./logsheets/AAOT_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='NRMCB' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1F4AWv_seI-DQJ_Gp_N2ziwvGyjnc4KC92GGNXrJRek4/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/NRMCB_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='HCMR-1' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/13DcVK2mzSxMJoFydSBaIMmj7Td1_JapEvcY2bmZTyLc/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/HCMR-1_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='IUIEilat' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1qIwi1nZu4OBiriCzn1fEG1fyG8-3wSVvwzsMiH6JTwk/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/IUIEilat_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='UMF' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1-1VsUUbRtKselxu-y2BghRIrJdaf74SbmvK42ntvd20/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/UMF_water_column_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='LMO' - sampling_strategy='water_column' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1AvQMYcS0tdNMw6Er8zUarQg1a_wrshhnkTS6RuI1FJQ/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/LMO_water_column_sampling_validated.csv\n",
      "Observatory ESC68N lacks valid sheet URL for soft_sediment\n",
      "Observatory Bergen lacks valid sheet URL for soft_sediment\n",
      "Observatory MBAL4 lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='BPNS' - sampling_strategy='soft_sediment' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1zc0bZdpl-Eoi35lI_5BGkElbscplyQRyNPLkSgeEyEQ/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/BPNS_soft_sediment_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='ROSKOGO' - sampling_strategy='soft_sediment' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1M0ytBWbUDP0YthGtTVtdIaX2cQUxF_uNIJBHIXREoX8/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 66 records leaving 155.\n",
      "Written ./logsheets/ROSKOGO_soft_sediment_sampling_validated.csv\n",
      "Observatory VB lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='OOB' - sampling_strategy='soft_sediment' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1J469_ljfxM9NhOEyRmvWQNOXX7dujxBy1opU6ROmDv8/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 93 records leaving 133.\n",
      "Written ./logsheets/OOB_soft_sediment_sampling_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='EMT21' - sampling_strategy='soft_sediment' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1sBB0x6h-prnUHMcOfms_7qSqTn6zeGVriitTysceoT0/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 129 records leaving 48.\n",
      "Written ./logsheets/EMT21_soft_sediment_sampling_validated.csv\n",
      "Observatory PiEGetxo lacks valid sheet URL for soft_sediment\n",
      "Observatory Plenzia lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='RFormosa' - sampling_strategy='soft_sediment' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/17rqrZ-qrDP77SpoEyBFO17wewp98a-tLBWTlBAn6ZCc/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/RFormosa_soft_sediment_sampling_validated.csv\n",
      "Observatory OSD74 lacks valid sheet URL for soft_sediment\n",
      "Observatory AAOT lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='NRMCB' - sampling_strategy='soft_sediment' - sheet_type='sampling'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1a19q3w2sP7dae8HEzT5TdmfqhRQQd3GItFqiYxWJlxs/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Written ./logsheets/NRMCB_soft_sediment_sampling_validated.csv\n",
      "Observatory HCMR-1 lacks valid sheet URL for soft_sediment\n",
      "Observatory IUIEilat lacks valid sheet URL for soft_sediment\n",
      "Observatory LMO lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='ESC68N' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/11_Eu0W1-sDiuzKx1cIl6YuxjRHmWezN6u9v3Ly8JZ3A/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Discarded 31 records leaving 120.\n",
      "Written ./logsheets/ESC68N_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='Bergen' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1HuXHiUJICZrmCrJ4EZDyU5aSCMzDAc1cy_tne5YVPTg/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/Bergen_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='MBAL4' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1xfrqraPa0auQ1O-C9RUo68RhxrPCDWkVMCAUbj79AZI/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/MBAL4_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='BPNS' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1mEi4Bd2YR63WD0j54FQ6QkzcUw_As9Wilue9kaXO2DE/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Discarded 1 records leaving 320.\n",
      "Written ./logsheets/BPNS_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='ROSKOGO' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1BCu2pbuIS4f-yrw5Kw4uzfO9v6ryZJBtSF5WBLWG_-E/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/ROSKOGO_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='VB' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1kSlTcNfXaCQv7fIKVbBnt5PmRW3_H7Trryh4FJHyLkE/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Discarded 26 records leaving 754.\n",
      "Written ./logsheets/VB_water_column_measured_validated.csv\n",
      "Observatory OOB lacks valid sheet URL for water_column\n",
      "\n",
      "\n",
      "Processing observatory_id='EMT21' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1RutVpduwL1mEed5jC2zLbs0DgkzAwZdsJ27fg3kb0Yg/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/EMT21_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='PiEGetxo' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1KGcishLP5eAn6ZCnixn5wZIez1Y9MgmYoch2s7aefKM/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/PiEGetxo_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='RFormosa' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/15f_yqrhvOr1MW-SHuv0JiKf0HRDy81uGZapJANxL54k/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/RFormosa_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='OSD74' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1VATpzmhwmk8sYkhEjCbDUZHRiYuNGpSRefhXthZRbfQ/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/OSD74_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='AAOT' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1hvLkBwiKTGTJDx19m_8e7qJ2lm9bwLLeVztMpxTLqnk/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/AAOT_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='NRMCB' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1F4AWv_seI-DQJ_Gp_N2ziwvGyjnc4KC92GGNXrJRek4/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/NRMCB_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='HCMR-1' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/13DcVK2mzSxMJoFydSBaIMmj7Td1_JapEvcY2bmZTyLc/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/HCMR-1_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='IUIEilat' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1qIwi1nZu4OBiriCzn1fEG1fyG8-3wSVvwzsMiH6JTwk/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/IUIEilat_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='UMF' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1-1VsUUbRtKselxu-y2BghRIrJdaf74SbmvK42ntvd20/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/UMF_water_column_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='LMO' - sampling_strategy='water_column' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1AvQMYcS0tdNMw6Er8zUarQg1a_wrshhnkTS6RuI1FJQ/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/LMO_water_column_measured_validated.csv\n",
      "Observatory ESC68N lacks valid sheet URL for soft_sediment\n",
      "Observatory Bergen lacks valid sheet URL for soft_sediment\n",
      "Observatory MBAL4 lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='BPNS' - sampling_strategy='soft_sediment' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1zc0bZdpl-Eoi35lI_5BGkElbscplyQRyNPLkSgeEyEQ/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Discarded 32 records leaving 143.\n",
      "Written ./logsheets/BPNS_soft_sediment_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='ROSKOGO' - sampling_strategy='soft_sediment' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1M0ytBWbUDP0YthGtTVtdIaX2cQUxF_uNIJBHIXREoX8/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/ROSKOGO_soft_sediment_measured_validated.csv\n",
      "Observatory VB lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='OOB' - sampling_strategy='soft_sediment' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1J469_ljfxM9NhOEyRmvWQNOXX7dujxBy1opU6ROmDv8/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Discarded 14 records leaving 118.\n",
      "Written ./logsheets/OOB_soft_sediment_measured_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='EMT21' - sampling_strategy='soft_sediment' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1sBB0x6h-prnUHMcOfms_7qSqTn6zeGVriitTysceoT0/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/EMT21_soft_sediment_measured_validated.csv\n",
      "Observatory PiEGetxo lacks valid sheet URL for soft_sediment\n",
      "Observatory Plenzia lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='RFormosa' - sampling_strategy='soft_sediment' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/17rqrZ-qrDP77SpoEyBFO17wewp98a-tLBWTlBAn6ZCc/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Discarded 1 records leaving 84.\n",
      "Written ./logsheets/RFormosa_soft_sediment_measured_validated.csv\n",
      "Observatory OSD74 lacks valid sheet URL for soft_sediment\n",
      "Observatory AAOT lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='NRMCB' - sampling_strategy='soft_sediment' - sheet_type='measured'\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1a19q3w2sP7dae8HEzT5TdmfqhRQQd3GItFqiYxWJlxs/gviz/tq?tqx=out:csv&sheet=measured\n",
      "Written ./logsheets/NRMCB_soft_sediment_measured_validated.csv\n",
      "Observatory HCMR-1 lacks valid sheet URL for soft_sediment\n",
      "Observatory IUIEilat lacks valid sheet URL for soft_sediment\n",
      "Observatory LMO lacks valid sheet URL for soft_sediment\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import pydantic\n",
    "from validation_classes import samplingModel, measuredModel\n",
    "\n",
    "def get_sheet(sheet_type: str, sheet_link: str, format_type: str = \"json\") -> pd.core.frame.DataFrame:\n",
    "        \"\"\"Returns a Pandas dataframe of the 'sampling' or 'measured' sheets\n",
    "        from the observatories' Google Sheets.\n",
    "\n",
    "        CSV has a problem with the word \"blank\" in the replicated field.\n",
    "        But none of the others work because of the header (not sure why only\n",
    "        CSV doesnt have the header.\n",
    "\n",
    "        TODO sort out the header parsing from the Google Sheet response.\n",
    "        \"\"\"\n",
    "        sampling_sheet_base = sheet_link.split(\"/edit\")[0]\n",
    "        if format_type == \"json\":\n",
    "            #should return json\n",
    "            sampling_sheet_suffix = f\"/gviz/tq?tqx=sheet={sheet_type}\"\n",
    "            sample_sheet_link = sampling_sheet_base + sampling_sheet_suffix\n",
    "            print(f\"Sample sheet link: {sample_sheet_link}\")\n",
    "            df = pd.read_json(sample_sheet_link)\n",
    "            \n",
    "        elif format_type == \"csv\":\n",
    "            sampling_sheet_suffix = f\"/gviz/tq?tqx=out:csv&sheet={sheet_type}\"\n",
    "            sample_sheet_link = sampling_sheet_base + sampling_sheet_suffix\n",
    "            print(f\"Sample sheet link: {sample_sheet_link}\")\n",
    "\n",
    "            # Note that even if we force the replicate field to be a string, it doesnt \n",
    "            # recognise \"blank\" as a string, it's still None\n",
    "            #df = pd.read_csv(sample_sheet_link, encoding='utf-8', dtype={\"replicate\": str})\n",
    "            # If we force them to ints the NaNs become NA as noted above\n",
    "            #df = pd.read_csv(sample_sheet_link, encoding='utf-8', dtype={\"replicate\": int})\n",
    "            \n",
    "            # Here we don't force ints with NaNs to \"Int64\", but\n",
    "            # let the later validator coerce floats and ints to string | None            \n",
    "            df = pd.read_csv(sample_sheet_link, encoding='utf-8')\n",
    "            \n",
    "        elif format_type == \"excel\":\n",
    "            sampling_sheet_suffix = f\"/gviz/tq?tqx=out:tsv-xlsx&sheet={sheet_type}\"\n",
    "            sample_sheet_link = sampling_sheet_base + sampling_sheet_suffix\n",
    "            print(f\"Sample sheet link: {sample_sheet_link}\")\n",
    "            df = pd.read_excel(sample_sheet_link, engine='openpyxl')\n",
    "        elif format_type == \"json\": \n",
    "            sampling_sheet_suffix = f\"/gviz/tq?tqx=out:json&sheet={sheet_type}\"\n",
    "            sample_sheet_link = sampling_sheet_base + sampling_sheet_suffix\n",
    "            print(f\"Sample sheet link: {sample_sheet_link}\")\n",
    "            df = pd.read_json(sample_sheet_link)\n",
    "        elif format_type == \"tsv\": \n",
    "            sampling_sheet_suffix = f\"/gviz/tq?tqx=out:tsv&sheet={sheet_type}\"\n",
    "            sample_sheet_link = sampling_sheet_base + sampling_sheet_suffix\n",
    "            print(f\"Sample sheet link: {sample_sheet_link}\")\n",
    "            df = pd.read_csv(sample_sheet_link,  sep='\\t')\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognised {format_type=}\")\n",
    "        return df\n",
    "\n",
    "def parse_sample_sheets(sampling_strategy: str, sheet_type: str, addresses: list[str, str]) -> None:\n",
    "    \n",
    "    for observatory in addresses:\n",
    "        observatory_id, sheet_link = observatory\n",
    "        #print(f\"Observatory_id {observatory_id} sheet_link {sheet_link}\")\n",
    "        if not isinstance(sheet_link, str):\n",
    "            #print(f\"This is the sheet_link type {type(sheet_link)}\")\n",
    "            if isinstance(sheet_link, float): \n",
    "                if math.isnan(sheet_link):\n",
    "                    print(f\"Observatory {observatory_id} lacks valid sheet URL for {sampling_strategy}\")\n",
    "                    continue\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown link {sheet_link} to observatory {observatory_id}\")\n",
    "        else:\n",
    "\n",
    "            if observatory_id == \"Plenzia\": continue # Sheets not publically available\n",
    "            # UMF soft_sed has two source_mat_ids\n",
    "            if sampling_strategy == \"soft_sediment\" and observatory_id == \"UMF\":\n",
    "                continue\n",
    "            \n",
    "            # if observatory_id not in [\"OSD74\", \"AAOT\"]:\n",
    "            #     continue\n",
    "            # if sampling_strategy != \"water_column\":\n",
    "            #     continue\n",
    "    \n",
    "            print(f\"\\n\\nProcessing {observatory_id=} - {sampling_strategy=} - {sheet_type=}\")\n",
    "            # Assuming either 'sampling' or 'measured' for sheet_type\n",
    "            df = get_sheet(sheet_type, sheet_link, format_type=\"csv\")\n",
    "            \n",
    "            data_records_all = df.to_dict(orient=\"records\")\n",
    "    \n",
    "            # Many sheets have partially filled rows\n",
    "            # The source_mat_id is auto-formatted and the PRIMARY_KEY\n",
    "            # Therefore filter records on source_mat_id\n",
    "            def filter_on_source_mat_id(d):\n",
    "                # Bergen has it as source_material_id\n",
    "                try:\n",
    "                    value = d[\"source_mat_id\"]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        value = d[\"source_material_id\"]\n",
    "                    except KeyError:\n",
    "                        raise ValueError(\"Cannot find source_mat_id field\")\n",
    "                if isinstance(value, float):\n",
    "                    if math.isnan(value):\n",
    "                        return False\n",
    "                elif value is None:\n",
    "                    return False\n",
    "                # Remove mis-formatted\n",
    "                elif len(value.split(\"_\")) < 6:\n",
    "                    return False\n",
    "                #Edge case of this otherwise blank entry having 6 \"bits\"\n",
    "                elif value == \"EMOBON_VB_Wa_230509_um_\":\n",
    "                    return False \n",
    "                else:\n",
    "                    return True\n",
    "                \n",
    "            data_records_filtered = list(filter(filter_on_source_mat_id, data_records_all))\n",
    "    \n",
    "            if len(data_records_all) > len(data_records_filtered):\n",
    "                print(f\"Discarded {len(data_records_all) - len(data_records_filtered)} records leaving {len(data_records_filtered)}.\")\n",
    "            \n",
    "            validator = validator_classes[sheet_type]\n",
    "            validated_rows = [validator(**row).model_dump() for row in data_records_filtered]\n",
    "    \n",
    "            save_dir = \"./logsheets\"\n",
    "            outfile_name = f\"{observatory_id}_{sampling_strategy}_{sheet_type}_validated.csv\"\n",
    "            ndf = pd.DataFrame.from_records(validated_rows, index=\"source_mat_id\")\n",
    "            ndf.to_csv(os.path.join(save_dir, outfile_name))\n",
    "            print(f\"Written {os.path.join(save_dir, outfile_name)}\")\n",
    "\n",
    "validator_classes = {\"sampling\": samplingModel, \"measured\": measuredModel}\n",
    "#Get list of observatory ids\n",
    "df = pd.read_csv(\"./governance/observatories_validated.csv\")\n",
    "observatory_ids = [id[0] for id in df[[\"observatory_id\"]].values.tolist()]\n",
    "print(f\"{observatory_ids=}\")\n",
    "# Get list of all URL links to sampling sheets\n",
    "# NB  you cant use a \"with\" closure here when reading the Pandas df\n",
    "governance_logsheets_validated_csv = \"./governance/logsheets_validated.csv\"\n",
    "df = pd.read_csv(governance_logsheets_validated_csv)\n",
    "water_column_sheet_addresses = df[[\"observatory_id\", \"water_column\"]].values.tolist()\n",
    "soft_sediment_sheet_addresses  = df[[\"observatory_id\", \"soft_sediment\"]].values.tolist()\n",
    "    \n",
    "parse_sample_sheets(\"water_column\", \"sampling\", water_column_sheet_addresses)\n",
    "parse_sample_sheets(\"soft_sediment\", \"sampling\", soft_sediment_sheet_addresses)\n",
    "parse_sample_sheets(\"water_column\", \"measured\", water_column_sheet_addresses)\n",
    "parse_sample_sheets(\"soft_sediment\", \"measured\", soft_sediment_sheet_addresses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa1b378-bbd4-4403-ae00-37c5b5ba8b82",
   "metadata": {},
   "source": [
    "# Validate the Observatory sheets the EMO-BON-Metadata Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8a1f67c-e5a8-445d-ac90-1ad4bad88180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "\n",
      "Processing observatory_id='ESC68N' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/11_Eu0W1-sDiuzKx1cIl6YuxjRHmWezN6u9v3Ly8JZ3A/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/11_Eu0W1-sDiuzKx1cIl6YuxjRHmWezN6u9v3Ly8JZ3A/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/ESC68N_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='Bergen' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1HuXHiUJICZrmCrJ4EZDyU5aSCMzDAc1cy_tne5YVPTg/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1HuXHiUJICZrmCrJ4EZDyU5aSCMzDAc1cy_tne5YVPTg/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/Bergen_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='MBAL4' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1xfrqraPa0auQ1O-C9RUo68RhxrPCDWkVMCAUbj79AZI/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1xfrqraPa0auQ1O-C9RUo68RhxrPCDWkVMCAUbj79AZI/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/MBAL4_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='BPNS' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1mEi4Bd2YR63WD0j54FQ6QkzcUw_As9Wilue9kaXO2DE/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1mEi4Bd2YR63WD0j54FQ6QkzcUw_As9Wilue9kaXO2DE/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/BPNS_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='ROSKOGO' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1BCu2pbuIS4f-yrw5Kw4uzfO9v6ryZJBtSF5WBLWG_-E/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1BCu2pbuIS4f-yrw5Kw4uzfO9v6ryZJBtSF5WBLWG_-E/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/ROSKOGO_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='VB' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1kSlTcNfXaCQv7fIKVbBnt5PmRW3_H7Trryh4FJHyLkE/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1kSlTcNfXaCQv7fIKVbBnt5PmRW3_H7Trryh4FJHyLkE/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/VB_water_column_observatory_validated.csv\n",
      "Observatory OOB lacks valid sheet URL for water_column\n",
      "\n",
      "\n",
      "Processing observatory_id='EMT21' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1RutVpduwL1mEed5jC2zLbs0DgkzAwZdsJ27fg3kb0Yg/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1RutVpduwL1mEed5jC2zLbs0DgkzAwZdsJ27fg3kb0Yg/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/EMT21_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='PiEGetxo' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1KGcishLP5eAn6ZCnixn5wZIez1Y9MgmYoch2s7aefKM/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1KGcishLP5eAn6ZCnixn5wZIez1Y9MgmYoch2s7aefKM/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/PiEGetxo_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='RFormosa' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/15f_yqrhvOr1MW-SHuv0JiKf0HRDy81uGZapJANxL54k/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/15f_yqrhvOr1MW-SHuv0JiKf0HRDy81uGZapJANxL54k/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/RFormosa_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='OSD74' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1VATpzmhwmk8sYkhEjCbDUZHRiYuNGpSRefhXthZRbfQ/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1VATpzmhwmk8sYkhEjCbDUZHRiYuNGpSRefhXthZRbfQ/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/OSD74_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='AAOT' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1hvLkBwiKTGTJDx19m_8e7qJ2lm9bwLLeVztMpxTLqnk/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1hvLkBwiKTGTJDx19m_8e7qJ2lm9bwLLeVztMpxTLqnk/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/AAOT_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='NRMCB' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1F4AWv_seI-DQJ_Gp_N2ziwvGyjnc4KC92GGNXrJRek4/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1F4AWv_seI-DQJ_Gp_N2ziwvGyjnc4KC92GGNXrJRek4/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/NRMCB_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='HCMR-1' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/13DcVK2mzSxMJoFydSBaIMmj7Td1_JapEvcY2bmZTyLc/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/13DcVK2mzSxMJoFydSBaIMmj7Td1_JapEvcY2bmZTyLc/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/HCMR-1_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='IUIEilat' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1qIwi1nZu4OBiriCzn1fEG1fyG8-3wSVvwzsMiH6JTwk/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1qIwi1nZu4OBiriCzn1fEG1fyG8-3wSVvwzsMiH6JTwk/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/IUIEilat_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='UMF' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1-1VsUUbRtKselxu-y2BghRIrJdaf74SbmvK42ntvd20/edit#gid=2052143695\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1-1VsUUbRtKselxu-y2BghRIrJdaf74SbmvK42ntvd20/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/UMF_water_column_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='LMO' - sampling_strategy='water_column' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1AvQMYcS0tdNMw6Er8zUarQg1a_wrshhnkTS6RuI1FJQ/edit#gid=2052143695\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1AvQMYcS0tdNMw6Er8zUarQg1a_wrshhnkTS6RuI1FJQ/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/LMO_water_column_observatory_validated.csv\n",
      "Observatory ESC68N lacks valid sheet URL for soft_sediment\n",
      "Observatory Bergen lacks valid sheet URL for soft_sediment\n",
      "Observatory MBAL4 lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='BPNS' - sampling_strategy='soft_sediment' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1zc0bZdpl-Eoi35lI_5BGkElbscplyQRyNPLkSgeEyEQ/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1zc0bZdpl-Eoi35lI_5BGkElbscplyQRyNPLkSgeEyEQ/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/BPNS_soft_sediment_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='ROSKOGO' - sampling_strategy='soft_sediment' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1M0ytBWbUDP0YthGtTVtdIaX2cQUxF_uNIJBHIXREoX8/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1M0ytBWbUDP0YthGtTVtdIaX2cQUxF_uNIJBHIXREoX8/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/ROSKOGO_soft_sediment_observatory_validated.csv\n",
      "Observatory VB lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='OOB' - sampling_strategy='soft_sediment' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1J469_ljfxM9NhOEyRmvWQNOXX7dujxBy1opU6ROmDv8/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1J469_ljfxM9NhOEyRmvWQNOXX7dujxBy1opU6ROmDv8/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/OOB_soft_sediment_observatory_validated.csv\n",
      "\n",
      "\n",
      "Processing observatory_id='EMT21' - sampling_strategy='soft_sediment' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1sBB0x6h-prnUHMcOfms_7qSqTn6zeGVriitTysceoT0/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1sBB0x6h-prnUHMcOfms_7qSqTn6zeGVriitTysceoT0/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/EMT21_soft_sediment_observatory_validated.csv\n",
      "Observatory PiEGetxo lacks valid sheet URL for soft_sediment\n",
      "Observatory Plenzia lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='RFormosa' - sampling_strategy='soft_sediment' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/17rqrZ-qrDP77SpoEyBFO17wewp98a-tLBWTlBAn6ZCc/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/17rqrZ-qrDP77SpoEyBFO17wewp98a-tLBWTlBAn6ZCc/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/RFormosa_soft_sediment_observatory_validated.csv\n",
      "Observatory OSD74 lacks valid sheet URL for soft_sediment\n",
      "Observatory AAOT lacks valid sheet URL for soft_sediment\n",
      "\n",
      "\n",
      "Processing observatory_id='NRMCB' - sampling_strategy='soft_sediment' - sheet_type='observatory'\n",
      "Sheet link: https://docs.google.com/spreadsheets/d/1a19q3w2sP7dae8HEzT5TdmfqhRQQd3GItFqiYxWJlxs/edit?usp=sharing\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1a19q3w2sP7dae8HEzT5TdmfqhRQQd3GItFqiYxWJlxs/gviz/tq?tqx=out:csv&sheet=observatory\n",
      "Written logsheets/NRMCB_soft_sediment_observatory_validated.csv\n",
      "Observatory HCMR-1 lacks valid sheet URL for soft_sediment\n",
      "Observatory IUIEilat lacks valid sheet URL for soft_sediment\n",
      "Observatory LMO lacks valid sheet URL for soft_sediment\n"
     ]
    }
   ],
   "source": [
    "# Validate the Observatory sheets in the EMO-BON-Metadata Google Sheets\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath \n",
    "from validation_classes import observatoryModel\n",
    "\n",
    "def get_sheet(sheet_link: str) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Returns a Pandas dataframe of the 'observatory' sheets\n",
    "    from the observatories' Google Sheets.\n",
    "    \"\"\"\n",
    "    print(f\"Sheet link: {sheet_link}\")\n",
    "    sampling_sheet_base   = sheet_link.split(\"/edit\")[0]\n",
    "    sampling_sheet_suffix = f\"/gviz/tq?tqx=out:csv&sheet=observatory\"\n",
    "    sample_sheet_link     = sampling_sheet_base + sampling_sheet_suffix\n",
    "    print(f\"Sample sheet link: {sample_sheet_link}\")         \n",
    "    df = pd.read_csv(sample_sheet_link, encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "def parse_sample_sheets(sampling_strategy: str, sheet_type: str, addresses: list[str, str]) -> None:\n",
    "    \n",
    "    for observatory in addresses:\n",
    "        observatory_id, sheet_link = observatory\n",
    "        #print(f\"Observatory_id {observatory_id} sheet_link {sheet_link}\")\n",
    "        if not isinstance(sheet_link, str):\n",
    "            #print(f\"This is the sheet_link type {type(sheet_link)}\")\n",
    "            if isinstance(sheet_link, float): \n",
    "                if math.isnan(sheet_link):\n",
    "                    print(f\"Observatory {observatory_id} lacks valid sheet URL for {sampling_strategy}\")\n",
    "                    continue\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown link {sheet_link} to observatory {observatory_id}\")\n",
    "        else:\n",
    "\n",
    "            if observatory_id    == \"Plenzia\": continue # Sheets not publically available\n",
    "            # UMF soft_sed has two source_mat_ids\n",
    "            if sampling_strategy == \"soft_sediment\" and observatory_id == \"UMF\":\n",
    "                continue\n",
    "            \n",
    "            # if observatory_id not in [\"OSD74\", \"AAOT\"]:\n",
    "            #     continue\n",
    "            # if sampling_strategy != \"water_column\":\n",
    "            #     continue\n",
    "    \n",
    "            print(f\"\\n\\nProcessing {observatory_id=} - {sampling_strategy=} - {sheet_type=}\")\n",
    "            df: pd.core.frame.DataFrame = get_sheet(sheet_link)\n",
    "\n",
    "            # Note there is only one row per sheet\n",
    "            data_records_all = df.to_dict(orient=\"records\")\n",
    "\n",
    "            #pprint(data_records_all)\n",
    "\n",
    "            #Get the obs_id from the only row\n",
    "            obs_id = data_records_all[0][\"obs_id\"]\n",
    "            assert observatory_id == obs_id, f\"Error: {observatory_id=} != {obs_id=}\"\n",
    "                           \n",
    "            if len(data_records_all) != 1:\n",
    "                raise RuntimeError(f\"Error: {len(data_records_all)} != 1\")\n",
    "            \n",
    "            validated_rows = [observatoryModel(**row).model_dump() for row in data_records_all]\n",
    "    \n",
    "            save_dir     = Path(\"./logsheets\")\n",
    "            outfile_name = Path(f\"{observatory_id}_{sampling_strategy}_{sheet_type}_validated.csv\")\n",
    "            ndf          = pd.DataFrame.from_records(validated_rows, index=\"obs_id\")\n",
    "            out_file     = PurePath(save_dir, outfile_name)\n",
    "            ndf.to_csv(out_file)\n",
    "            print(f\"Written {out_file}\")\n",
    "\n",
    "#Get list of observatory ids\n",
    "#df = pd.read_csv(\"./governance/observatories_validated.csv\")\n",
    "#observatory_ids = [id[0] for id in df[[\"observatory_id\"]].values.tolist()]\n",
    "#print(f\"{observatory_ids=}\")\n",
    "\n",
    "# Get list of all URL links to sampling sheets\n",
    "# NB  you cant use a \"with\" closure here when reading the Pandas df\n",
    "df = pd.read_csv(Path(\"./governance/logsheets_validated.csv\"))\n",
    "water_column_sheet_addresses   = df[[\"observatory_id\", \"water_column\"]].values.tolist()\n",
    "soft_sediment_sheet_addresses  = df[[\"observatory_id\", \"soft_sediment\"]].values.tolist()\n",
    "    \n",
    "parse_sample_sheets(\"water_column\", \"observatory\", water_column_sheet_addresses)\n",
    "parse_sample_sheets(\"soft_sediment\", \"observatory\", soft_sediment_sheet_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0a641-6fa8-48d5-b3d3-0785beaf2f68",
   "metadata": {},
   "source": [
    "# Combined meta-table for each observatory of all validated logsheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3cbb42-7bd0-4a45-9ee4-a6d30ce44758",
   "metadata": {},
   "source": [
    "The source_mat_id is the unique key or identifier that links the records in the Batch run_information sheets ([run-information-batch-001.csv](https://raw.githubusercontent.com/emo-bon/sequencing-data/main/shipment/batch-001/run-information-batch-001.csv) and [run-information-batch-002.csv](https://raw.githubusercontent.com/emo-bon/sequencing-data/main/shipment/batch-002/run-information-batch-002.csv)) to the sampling events in the \"sampling\" and \"measured\" sheets of the observatory logsheets (Google Sheets) (e.g. [ESC68N](https://docs.google.com/spreadsheets/d/11_Eu0W1-sDiuzKx1cIl6YuxjRHmWezN6u9v3Ly8JZ3A/edit?gid=0#gid=0)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33792f86-8da9-4cd5-9986-29a80aedfbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observatory ESC68N-water_column has 150 sampling events.\n",
      "136 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 14 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory Bergen-water_column has 140 sampling events.\n",
      "140 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 0 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory MBAL4-water_column has 80 sampling events.\n",
      "72 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 8 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory BPNS-water_column has 320 sampling events.\n",
      "302 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 18 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory BPNS-soft_sediment has 171 sampling events.\n",
      "163 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 8 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory ROSKOGO-water_column has 291 sampling events.\n",
      "272 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 17 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory ROSKOGO-soft_sediment has 155 sampling events.\n",
      "149 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 6 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory VB-water_column has 824 sampling events.\n",
      "806 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 18 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory OOB-soft_sediment has 133 sampling events.\n",
      "126 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 7 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory EMT21-water_column has 265 sampling events.\n",
      "251 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 14 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory EMT21-soft_sediment has 48 sampling events.\n",
      "48 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 0 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory PiEGetxo-water_column has 239 sampling events.\n",
      "224 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 13 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory RFormosa-water_column has 170 sampling events.\n",
      "156 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 14 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory RFormosa-soft_sediment has 85 sampling events.\n",
      "79 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 6 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory OSD74-water_column has 170 sampling events.\n",
      "157 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 13 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory AAOT-water_column has 400 sampling events.\n",
      "382 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 18 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory NRMCB-water_column has 382 sampling events.\n",
      "364 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 18 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory NRMCB-soft_sediment has 95 sampling events.\n",
      "86 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 9 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory HCMR-1-water_column has 144 sampling events.\n",
      "134 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 10 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory IUIEilat-water_column has 60 sampling events.\n",
      "46 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 14 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "Observatory LMO-water_column has 100 sampling events.\n",
      "100 have no ref_code (i.e. they were not sent for sequencing), \n",
      "0 'sampling' events have a refcode but no 'measured' data with the corresponding source_mat_id: \n",
      "A total of 0 sampling events with refcode and measured sheet were found.\n",
      "\n",
      "There are 227 total ref_codes assigned\n",
      "A total of 2 sequencing event in the Batch 1 & 2 run_information sheets have refcodes that match source_mat_ids in the sample sheets that have duplicate entries\n",
      "Total number of combined sampling events with ref_codes: 225\n",
      "Total number of all_source_mat_ids_from_sheets: 4422 of which 56 were duplicates\n",
      "A total of 0 source_mat_ids in the batch 1 & 2 run information sheets are missing from the observatory sampling sheets\n",
      "\n",
      "Total combined_events: 225 \n",
      "Missing events: 0 \n",
      "EMO BON ref_codes in run_information sheets: 227 \n",
      "Events ignored due to duplications in sampling sheets: 2 \n",
      "225 + 0 = 227 - 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import validators\n",
    "import collections\n",
    "from pprint import pprint\n",
    "\n",
    "LOGSHEETS_PATH = \"./logsheets\"\n",
    "# These are real duplicates\n",
    "KNOWN_DUPLICATES = [\"EMOBON_ROSKOGO_Wa_210618_3um_1\", \"EMOBON_PiEGetxo_Wa_210824_3um_blank\"]\n",
    "\n",
    "def get_observatory_data() -> list[str, str, str]:\n",
    "    # Get list of observatory_ids\n",
    "    df = pd.read_csv(\"./governance/logsheets_validated.csv\")\n",
    "    observatory_data = df[[\"observatory_id\", \"water_column\", \"soft_sediment\"]].values.tolist()\n",
    "    return observatory_data\n",
    "\n",
    "def get_all_refcodes() -> dict[str, str]:\n",
    "    batch1_run_info_path = \"https://raw.githubusercontent.com/emo-bon/sequencing-data/main/shipment/batch-001/run-information-batch-001.csv\"\n",
    "    batch2_run_info_path = \"https://raw.githubusercontent.com/emo-bon/sequencing-data/main/shipment/batch-002/run-information-batch-002.csv\"\n",
    "    # Get list of batch1 <source_mat_id>, <ref_code>'s\n",
    "    df = pd.read_csv(batch1_run_info_path)\n",
    "    refcodes = {}\n",
    "    for i in df[[\"source_material_id\", \"ref_code\"]].values.tolist():\n",
    "        assert i[0] not in refcodes, f\"{source_material_id} maybe duplicated\"\n",
    "        refcodes.update(dict([i]))\n",
    "    # Get list of batch2 <source_mat_id>, <ref_code>'s\n",
    "    df = pd.read_csv(batch2_run_info_path)\n",
    "    b2_refcodes = {}\n",
    "    for i in df[[\"source_material_id\", \"ref_code\"]].values.tolist():\n",
    "        assert i[0] not in refcodes, f\"{source_material_id} maybe duplicated\"\n",
    "        b2_refcodes.update(dict([i]))\n",
    "    refcodes.update(b2_refcodes)\n",
    "    return refcodes\n",
    "\n",
    "def parse_observatory_sample_type(observatory_id: str,\n",
    "                                  obs_refcodes: dict[str, str],\n",
    "                                  sampling_type: str,\n",
    "                                  save_table: bool = False,\n",
    "                                  verbose: bool = True) -> list[dict[str, str]]:\n",
    "    \"\"\"An observatory is an EMBRC station and it has an ID\n",
    "       Each observatory may take either or both of the \"water_column\" and \"soft_sediment\" sampling types\n",
    "       Each sampling type has both a \"sampling\" and \"measured\" sheet\n",
    "\n",
    "       This function returns a list of sampling events each of which is a dict with key/value pairs for each field and value\n",
    "    \"\"\"\n",
    "    \n",
    "    sampling_data_filename = f\"{observatory_id}_{sampling_type}_sampling_validated.csv\"\n",
    "    measured_data_filename = f\"{observatory_id}_{sampling_type}_measured_validated.csv\"\n",
    "\n",
    "    sampling_data = pd.read_csv(os.path.join(LOGSHEETS_PATH, sampling_data_filename))\n",
    "    measured_data = pd.read_csv(os.path.join(LOGSHEETS_PATH, measured_data_filename))\n",
    "\n",
    "    sampling_events = sampling_data.to_dict(orient=\"records\")\n",
    "    measured_events = measured_data.to_dict(orient=\"records\")\n",
    "\n",
    "    # To be returned\n",
    "    source_mat_ids_from_combined_events = []           # List of all source_mat_ids\n",
    "    all_sampling_source_mat_ids = sampling_data[\"source_mat_id\"].values.tolist()\n",
    "    missing_measured_but_refcode_present = 0           # Shouldn't happen if sheet is not broken\n",
    "    duplicates_ignored_counter = 0                     # How many known duplicate source_mat_ids in the sheets are we ignoring\n",
    "    combined_events = []                               # List of all sampling/measured events\n",
    "\n",
    "    # Internal \n",
    "    no_refcode_counter = 0 # Sampling events without a refcode ie not sent to sequencing\n",
    "    source_mat_ids_in_sampling_with_refcode_missing_from_measured = [] # Again shouldn't happen\n",
    "    refcodes_in_run_info = [] # List of refcodes matched to source_mat_ids\n",
    "    \n",
    "    for sampling_event in sampling_events:\n",
    "\n",
    "        # Checking consistency\n",
    "        # Does this sampling event have a ref_code\n",
    "        # If yes, then it should have both a sampling and measured sheet\n",
    "        # If no, we can ignore it\n",
    "        event_mat_id = sampling_event[\"source_mat_id\"]\n",
    "\n",
    "        # Two source_mat_id's in the Batch 1 & 2 run_informations match duplicate sampling events\n",
    "        # in the sampling sheets - here we ignore those two:\n",
    "        if event_mat_id in KNOWN_DUPLICATES:\n",
    "            duplicates_ignored_counter += 1\n",
    "            #print(f\"IGNORING DUP: {event_mat_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Hack for HCMR-1 replicates which are \"blank1\" and \"blank2\" in the sampling sheet\n",
    "        # become just blank in the measured and run_information sheet from where we get the refcodes\n",
    "        if event_mat_id == \"EMOBON_HCMR-1_Wa_210917_3um_blank1\":\n",
    "            event_mat_id = \"EMOBON_HCMR-1_Wa_210917_3um_blank\"\n",
    "        if event_mat_id == \"EMOBON_HCMR-1_Wa_210917_0.2um_blank1\":\n",
    "            event_mat_id = \"EMOBON_HCMR-1_Wa_210917_0.2um_blank\"\n",
    "        \n",
    "        try:\n",
    "            refcode = obs_refcodes[event_mat_id]\n",
    "        except KeyError:\n",
    "            no_refcode_counter += 1\n",
    "            # OK so has not been sent to sequencing; ignore\n",
    "            continue\n",
    "        \n",
    "        event_measured = False\n",
    "        for measured_event in measured_events:\n",
    "            \n",
    "            try:\n",
    "                measured_event[\"source_mat_id\"]\n",
    "            except KeyError:\n",
    "                print(f\"Key error: {measured_event}\")\n",
    "                raise KeyError\n",
    "                # Should not happen\n",
    "            if measured_event[\"source_mat_id\"] == event_mat_id:\n",
    "                event_measured = copy.deepcopy(measured_event)\n",
    "                break\n",
    "                \n",
    "        if not event_measured:\n",
    "            # sampling sheet source_mat_id has ref_code in run_information\n",
    "            # but the corresponding measured sheet lacks the same sources_mat_id\n",
    "            # This shouldn't happen unless the auto-formatting of the 'source_mat_id'\n",
    "            # field in the 'measured' sheet is broken - which is exactly what happened.\n",
    "            missing_measured_but_refcode_present += 1\n",
    "            source_mat_ids_in_sampling_with_refcode_missing_from_measured.append(event_mat_id)\n",
    "            continue\n",
    "        else:\n",
    "            sampling_event[\"ref_code\"] = refcode\n",
    "            if refcode in refcodes_in_run_info:\n",
    "                raise ValueError(f\"Error: {refcode=} match more that one sampling event \"\n",
    "                                 f\"with the {source_mat_id=}\"\n",
    "                                )\n",
    "            else:\n",
    "                refcodes_in_run_info.append(refcode)\n",
    "                # Delete the now duplicated source_mat_id in the combined event\n",
    "                del event_measured[\"source_mat_id\"]\n",
    "                source_mat_ids_from_combined_events.append(event_mat_id)\n",
    "                sampling_event.update(event_measured)\n",
    "                combined_events.append(sampling_event)\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "              f\"Observatory {observatory_id}-{sampling_type} has {len(sampling_events)} sampling events.\\n\"\n",
    "              f\"{no_refcode_counter} have no ref_code (i.e. they were not sent for sequencing), \\n\"\n",
    "              f\"{missing_measured_but_refcode_present} 'sampling' events have a refcode but no \"\n",
    "              f\"'measured' data with the corresponding source_mat_id: \\n\"\n",
    "              #f\"{source_mat_ids_in_sampling_with_refcode_missing_from_measured} \\n\"\n",
    "              f\"A total of {len(combined_events)} sampling events with refcode and measured sheet were found.\\n\"\n",
    "             )\n",
    "\n",
    "    # Did we find all the sampling events?\n",
    "    se = len(sampling_events)\n",
    "    ce = len(combined_events)\n",
    "    mmbrcp = missing_measured_but_refcode_present\n",
    "    nrc = no_refcode_counter\n",
    "    dc = duplicates_ignored_counter\n",
    "    assert se == (ce + nrc + mmbrcp + dc), \\\n",
    "        f\"Something is a foot: len(sampling_events) {se} != \" \\\n",
    "        f\"(len(combined_events) {ce} + no_refcode_counter {nrc} \" \\\n",
    "        f\"missing_measured_but_refcode_present {mmbrcp}) \" \\\n",
    "        f\"known duplicates ignored was {dc}\"\n",
    "\n",
    "    if len(combined_events) != 0 and save_table:\n",
    "        save_dir = \"./transformed\"\n",
    "        outfile_name = f\"{observatory_id}_{sampling_type}_combined_validated.csv\"\n",
    "        ndf = pd.DataFrame.from_records(combined_events, index=\"source_mat_id\")\n",
    "        ndf.to_csv(os.path.join(save_dir, outfile_name))\n",
    "\n",
    "    return(source_mat_ids_from_combined_events,\n",
    "           all_sampling_source_mat_ids,\n",
    "           missing_measured_but_refcode_present,\n",
    "           duplicates_ignored_counter,\n",
    "           combined_events\n",
    "           )\n",
    "\n",
    "def validate_observatories(observatory_data,\n",
    "                           obs_refcodes,\n",
    "                           save_table = False\n",
    "                          ) -> tuple[list, list, int, int, list]:\n",
    "\n",
    "    # To be returned\n",
    "    all_source_mat_ids_from_combined_events: list[str] = []\n",
    "    all_source_mat_ids_from_sheets: list[str] = []\n",
    "    all_missing_measured_but_refcode_present: int = 0\n",
    "    all_duplicates_ignored: int = 0\n",
    "    all_combined_events: list[list[str, ...]] = []\n",
    "    \n",
    "    for observatory_id, water_column, soft_sediment in observatory_data:\n",
    "    \n",
    "        if observatory_id == \"Plenzia\": continue # Data not public\n",
    "        if observatory_id == \"UMF\" and soft_sediment: continue # Broken sheet\n",
    "\n",
    "        #Surely there is a better way to do this\n",
    "        observatories_present = []\n",
    "        if validators.url(water_column):\n",
    "            observatories_present.append(\"water_column\")\n",
    "        if validators.url(soft_sediment):\n",
    "            observatories_present.append(\"soft_sediment\")\n",
    "\n",
    "        for sampling_strategy in observatories_present:\n",
    "                \n",
    "            r = parse_observatory_sample_type(observatory_id,\n",
    "                                              obs_refcodes,\n",
    "                                              sampling_strategy,\n",
    "                                              save_table\n",
    "                                             )                \n",
    "            \n",
    "            all_source_mat_ids_from_combined_events.extend(r[0]),\n",
    "            all_source_mat_ids_from_sheets.extend(r[1]),\n",
    "            # Cannot use += on tuple unpacking\n",
    "            all_missing_measured_but_refcode_present = all_missing_measured_but_refcode_present + r[2]\n",
    "            all_duplicates_ignored = all_duplicates_ignored + r[3]\n",
    "            all_combined_events.extend(r[4])\n",
    "            \n",
    "    return(all_source_mat_ids_from_combined_events,\n",
    "           all_source_mat_ids_from_sheets,\n",
    "           all_missing_measured_but_refcode_present,\n",
    "           all_duplicates_ignored,\n",
    "           all_combined_events\n",
    "           )\n",
    "\n",
    "############ VALIDATE OBSERVATORIES ###################################################\n",
    "\n",
    "#Get observatory data and ref_codes\n",
    "observatory_data: list[str, str, str] = get_observatory_data()\n",
    "obs_refcodes: dict[str, str] = get_all_refcodes()\n",
    "\n",
    "result = validate_observatories(observatory_data,\n",
    "                                 obs_refcodes,\n",
    "                                 save_table = True\n",
    "                                )\n",
    "                                 \n",
    "all_source_mat_ids_from_combined_events  = result[0]\n",
    "all_source_mat_ids_from_sheets           = result[1]\n",
    "all_missing_measured_but_refcode_present = result[2]\n",
    "all_duplicates_ignored                   = result[3]\n",
    "all_combined_events                      = result[4]\n",
    "\n",
    "############## REPORT STATISTICS ########################################################\n",
    "\n",
    "############### REFCODES ####################################\n",
    "print(f\"There are {len(obs_refcodes)} total ref_codes assigned\")\n",
    "# We are ignoring both of the duplicates but it's only 1 record expected missing from total_combined events\n",
    "\n",
    "############## DUPLICATES ###################################\n",
    "total_dups_ignored = int(all_duplicates_ignored /2)\n",
    "print(f\"A total of {total_dups_ignored} sequencing event in the Batch 1 & 2 run_information sheets \"\n",
    "      f\"have refcodes that match source_mat_ids in the sample sheets that have duplicate entries\"\n",
    "     )\n",
    "print(f\"Total number of combined sampling events with ref_codes: {len(all_combined_events)}\")\n",
    "duplicates = [source_mat_id for source_mat_id, count in collections.Counter(all_source_mat_ids_from_sheets).items() if count > 1]\n",
    "print(f\"Total number of all_source_mat_ids_from_sheets: {len(all_source_mat_ids_from_sheets)}\"\n",
    "      f\" of which {len(duplicates)} were duplicates\"\n",
    "     )\n",
    "\n",
    "############# SOURCE_MAT_IDS ################################\n",
    "missing_source_mat_ids =[]\n",
    "for source_mat_id in obs_refcodes: \n",
    "    # source_mat_ids are the keys in the refcode dict of the run_information\n",
    "    # print(f\"refcode from run_information: {refcode}\")\n",
    "\n",
    "    #Hack for HCMR-1\n",
    "    if source_mat_id == \"EMOBON_HCMR-1_Wa_210917_3um_blank\":\n",
    "        source_mat_id = \"EMOBON_HCMR-1_Wa_210917_3um_blank1\"\n",
    "    if source_mat_id == \"EMOBON_HCMR-1_Wa_210917_0.2um_blank\":\n",
    "        source_mat_id = \"EMOBON_HCMR-1_Wa_210917_0.2um_blank1\"\n",
    "    \n",
    "    if source_mat_id not in all_source_mat_ids_from_sheets:\n",
    "        #print(f\"source_mat_id {source_mat_id} is missing from the sampling sheets\")\n",
    "        \n",
    "        # Get close matches to missing source_mat_id\n",
    "        matches = difflib.get_close_matches(source_mat_id, all_source_mat_ids_from_sheets, n=3)\n",
    "        missing_source_mat_ids.append([source_mat_id, matches])\n",
    "        \n",
    "if missing_source_mat_ids:\n",
    "    print(\"\\n\\nThe missing source_mat_ids that are in the run information sheets are:\")\n",
    "    for missing in missing_source_mat_ids:\n",
    "        join = \" \".join(missing[1])\n",
    "        print(f\"Missing source_mat_id is {missing[0]} close matches are \\n\\t {join}\")\n",
    "    \n",
    "    for missing in missing_source_mat_ids:\n",
    "        print(missing)\n",
    "        \n",
    "print(f\"A total of {len(missing_source_mat_ids)} source_mat_ids \"\n",
    "      f\"in the batch 1 & 2 run information sheets are missing from the \"\n",
    "      f\"observatory sampling sheets\")\n",
    "\n",
    "missing = False # CAUTION: THIS SHOULD BE ZERO!\n",
    "counter = 0\n",
    "# TODO: take all_source_mat_ids_from_combined_events directly from all_combined_events rather than having\n",
    "# a separate list\n",
    "for source_mat_id in all_source_mat_ids_from_combined_events: \n",
    "    # source_mat_ids are the keys in the refcode dict of the run_information\n",
    "    #print(f\"source_mat_id: {source_mat_id}\")\n",
    "    if source_mat_id not in obs_refcodes:\n",
    "        #print(f\"source_mat_id {source_mat_id} is missing from the run_information\")\n",
    "        counter += 1\n",
    "        missing = True\n",
    "if missing:\n",
    "    print(f\"ERROR: A total of {counter} source_mat_ids \"\n",
    "          f\"in the sampling sheets that also have refcodes are missing from the \"\n",
    "          f\"Batch 1 & 2 run information sheets\")\n",
    "\n",
    "##################### SUMMARY #################################\n",
    "total = len(all_combined_events) + len(missing_source_mat_ids)\n",
    "print(\n",
    "    f\"\\nTotal combined_events: {len(all_combined_events)} \\n\" \n",
    "    f\"Missing events: {len(missing_source_mat_ids)} \\n\"\n",
    "    f\"EMO BON ref_codes in run_information sheets: {len(obs_refcodes)} \\n\"\n",
    "    f\"Events ignored due to duplications in sampling sheets: {total_dups_ignored} \\n\"\n",
    "    f\"{len(all_combined_events)} + {len(missing_source_mat_ids)} = {len(obs_refcodes)} - {total_dups_ignored}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b5e06b-a1b8-4661-afd2-3ae2a42b3103",
   "metadata": {},
   "source": [
    "# Create the single metadata table from the combined observatories tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0522c-c143-42f4-8d0f-db82b0e56e3f",
   "metadata": {},
   "source": [
    "Combined observatories metadata tables are in ./transformed and have the file name format:\n",
    "`<observatory_id>_<sampling_strategy>_combined_validated.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c07f7b5-9c18-4e11-9ee0-2e8061603b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 225 entries, 0 to 13\n",
      "Columns: 112 entries, source_mat_id to sampling_type\n",
      "dtypes: Int64(1), float64(57), object(54)\n",
      "memory usage: 198.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "FILE_PATH = \"./transformed\"\n",
    "\n",
    "csv_files = [f for f in os.listdir(FILE_PATH) if f.split(\".\")[1] == \"csv\"]\n",
    "\n",
    "frames  = []\n",
    "for obs in csv_files:\n",
    "    front = obs.split(\"_combined_validated.csv\")[0]\n",
    "    obs_id, strategy = front.split(\"_\", 1)\n",
    "    #print(f\"{obs_id=} -> - {strategy=}\")\n",
    "    df = pd.read_csv(os.path.join(FILE_PATH, obs), dtype={\"tax_id\": \"Int64\"}) # See note above\n",
    "    for index, event in df.iterrows():\n",
    "        df.loc[index, \"sampling_type\"] = strategy\n",
    "    frames.append(df)\n",
    "\n",
    "combined_df = pd.concat(frames)\n",
    "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "outfile_name = f\"Batch1and2_combined_logsheets_{today}.csv\"\n",
    "#combined_df.set_index(\"source_mat_id\")\n",
    "combined_df.to_csv(outfile_name, index=False)\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e0e5c-4aa2-4101-901d-a14d9bab9af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
