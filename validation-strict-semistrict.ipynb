{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae637b6-a712-4ec7-b2cb-4d8c11be9feb",
   "metadata": {},
   "source": [
    "### Pulls from the raw Obseravatory Google Sheets, does \"strict\" and \"semi-strict\" validation depending on constant\n",
    "(Lax is pointless as it should pass and write no errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9f2f9e9-b4db-4429-b30a-faa4bbf05c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mypy_ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext mypy_ipython\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Processing ESC68N...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/11_Eu0W1-sDiuzKx1cIl6YuxjRHmWezN6u9v3Ly8JZ3A/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 114 records leaving 150.\n",
      "All records passed!\n",
      "Processing Bergen...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1HuXHiUJICZrmCrJ4EZDyU5aSCMzDAc1cy_tne5YVPTg/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 280 in total\n",
      "Processing MBAL4...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1xfrqraPa0auQ1O-C9RUo68RhxrPCDWkVMCAUbj79AZI/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 72 in total\n",
      "Processing BPNS...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1mEi4Bd2YR63WD0j54FQ6QkzcUw_As9Wilue9kaXO2DE/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 596 in total\n",
      "Processing ROSKOGO...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1BCu2pbuIS4f-yrw5Kw4uzfO9v6ryZJBtSF5WBLWG_-E/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "All records passed!\n",
      "Processing VB...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1kSlTcNfXaCQv7fIKVbBnt5PmRW3_H7Trryh4FJHyLkE/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 32 records leaving 824.\n",
      "Errors were found... 1331 in total\n",
      "Observatory OOB does not do water_column\n",
      "Processing EMT21...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1RutVpduwL1mEed5jC2zLbs0DgkzAwZdsJ27fg3kb0Yg/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "All records passed!\n",
      "Processing PiEGetxo...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1KGcishLP5eAn6ZCnixn5wZIez1Y9MgmYoch2s7aefKM/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "All records passed!\n",
      "Processing RFormosa...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/15f_yqrhvOr1MW-SHuv0JiKf0HRDy81uGZapJANxL54k/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "All records passed!\n",
      "Processing OSD74...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1VATpzmhwmk8sYkhEjCbDUZHRiYuNGpSRefhXthZRbfQ/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 28 records leaving 170.\n",
      "Errors were found... 340 in total\n",
      "Processing AAOT...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1hvLkBwiKTGTJDx19m_8e7qJ2lm9bwLLeVztMpxTLqnk/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 188 records leaving 400.\n",
      "Errors were found... 1200 in total\n",
      "Processing NRMCB...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1F4AWv_seI-DQJ_Gp_N2ziwvGyjnc4KC92GGNXrJRek4/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 382 in total\n",
      "Processing HCMR-1...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/13DcVK2mzSxMJoFydSBaIMmj7Td1_JapEvcY2bmZTyLc/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 288 in total\n",
      "Processing IUIEilat...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1qIwi1nZu4OBiriCzn1fEG1fyG8-3wSVvwzsMiH6JTwk/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "All records passed!\n",
      "Processing UMF...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1-1VsUUbRtKselxu-y2BghRIrJdaf74SbmvK42ntvd20/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "All records passed!\n",
      "Processing LMO...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1AvQMYcS0tdNMw6Er8zUarQg1a_wrshhnkTS6RuI1FJQ/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 72 in total\n",
      "Observatory ESC68N does not do soft_sediment\n",
      "Observatory Bergen does not do soft_sediment\n",
      "Observatory MBAL4 does not do soft_sediment\n",
      "Processing BPNS...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1zc0bZdpl-Eoi35lI_5BGkElbscplyQRyNPLkSgeEyEQ/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 513 in total\n",
      "Processing ROSKOGO...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1M0ytBWbUDP0YthGtTVtdIaX2cQUxF_uNIJBHIXREoX8/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 66 records leaving 155.\n",
      "Errors were found... 473 in total\n",
      "Observatory VB does not do soft_sediment\n",
      "Processing OOB...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1J469_ljfxM9NhOEyRmvWQNOXX7dujxBy1opU6ROmDv8/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 93 records leaving 133.\n",
      "Errors were found... 399 in total\n",
      "Processing EMT21...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1sBB0x6h-prnUHMcOfms_7qSqTn6zeGVriitTysceoT0/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Discarded 129 records leaving 48.\n",
      "Errors were found... 144 in total\n",
      "Observatory PiEGetxo does not do soft_sediment\n",
      "Observatory Plenzia does not do soft_sediment\n",
      "Processing RFormosa...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/17rqrZ-qrDP77SpoEyBFO17wewp98a-tLBWTlBAn6ZCc/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 255 in total\n",
      "Observatory OSD74 does not do soft_sediment\n",
      "Observatory AAOT does not do soft_sediment\n",
      "Processing NRMCB...\n",
      "Sample sheet link: https://docs.google.com/spreadsheets/d/1a19q3w2sP7dae8HEzT5TdmfqhRQQd3GItFqiYxWJlxs/gviz/tq?tqx=out:csv&sheet=sampling\n",
      "Errors were found... 285 in total\n",
      "Observatory HCMR-1 does not do soft_sediment\n",
      "Observatory IUIEilat does not do soft_sediment\n",
      "Observatory LMO does not do soft_sediment\n"
     ]
    }
   ],
   "source": [
    "%load_ext mypy_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import validators\n",
    "from pathlib import Path, PurePath\n",
    "import pandas as pd\n",
    "from pydantic import ValidationError\n",
    "from pprint import pprint\n",
    "from validation_classes import samplingModel, measuredModel, samplingModelStrict, samplingModelSemiStrict\n",
    "from typing import Any, Union\n",
    "\n",
    "############################ CAUTION ##################################################\n",
    "STRICT: bool      = False  # As defined by Ioulia, dates corrected, NA's removed etc\n",
    "SEMI_STRICT: bool = True   # As defined by Ioulia but not checking for mandatory fields\n",
    "                     # ints and str coerced to floats when possible\n",
    "#######################################################################################\n",
    "\n",
    "def parse_sample_sheets(sampling_strategy: str,\n",
    "                        sheet_type: str,\n",
    "                        addresses: list[tuple[str, str]],\n",
    "                       ) -> None:\n",
    "    \n",
    "    for observatory in addresses:\n",
    "        observatory_id, sheet_link = observatory\n",
    "        #print(f\"Observatory_id {observatory_id} sheet_link {sheet_link}\")\n",
    "        if not isinstance(sheet_link, str):\n",
    "            #print(f\"This is the sheet_link type {type(sheet_link)}\")\n",
    "            if isinstance(sheet_link, float): \n",
    "                if math.isnan(sheet_link):\n",
    "                    print(f\"Observatory {observatory_id} does not do {sampling_strategy}\")\n",
    "                    continue\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown URL value {sheet_link} to observatory {observatory_id}\")\n",
    "        else:\n",
    "            if not validators.url(sheet_link):\n",
    "                raise ValueError(f\"URL {sheet_link=} is not valid\")\n",
    "\n",
    "            if observatory_id == \"Plenzia\": continue # Sheets not publically available\n",
    "            # UMF soft_sed has two source_mat_ids\n",
    "            if sampling_strategy == \"soft_sediment\" and observatory_id == \"UMF\":\n",
    "                continue\n",
    "    \n",
    "            print(f\"Processing {observatory_id}...\")\n",
    "            sampling_sheet_base: str = sheet_link.split(\"/edit\")[0]\n",
    "            sampling_sheet_suffix: str = \"/gviz/tq?tqx=out:csv&sheet=%s\"\n",
    "            sample_sheet_link: str = sampling_sheet_base + sampling_sheet_suffix % sheet_type\n",
    "            print(f\"Sample sheet link: {sample_sheet_link}\")\n",
    "            df: pd.core.frame.DataFrame = pd.read_csv(sample_sheet_link, encoding='utf-8')\n",
    "            data_records_all: dict[str, str] = df.to_dict(orient=\"records\")\n",
    "    \n",
    "            # Many sheets have partially filled rows\n",
    "            # The source_mat_id is manually curated and the PRIMARY_KEY\n",
    "            # Therefore filter records on source_mat_id\n",
    "            def filter_on_source_mat_id(d):\n",
    "                # Bergen has it as source_material_id\n",
    "                try:\n",
    "                    value: Union[str, float, None] = d[\"source_mat_id\"]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        value: Union[str, float, None] = d[\"source_material_id\"]\n",
    "                    except KeyError:\n",
    "                        raise ValueError(\"Cannot find source_mat_id field\")\n",
    "                if isinstance(value, float):\n",
    "                    if math.isnan(value):\n",
    "                        return False\n",
    "                elif value is None:\n",
    "                    return False\n",
    "                # Remove mis-formatted\n",
    "                elif len(value.split(\"_\")) < 6:\n",
    "                    return False\n",
    "                #Edge case of this otherwise blank entry having 6 \"bits\"\n",
    "                elif value == \"EMOBON_VB_Wa_230509_um_\":\n",
    "                    return False \n",
    "                else:\n",
    "                    return True\n",
    "\n",
    "            data_records_filtered: list[dict[str, str]] = list(filter(filter_on_source_mat_id, data_records_all))\n",
    "    \n",
    "            if len(data_records_all) > len(data_records_filtered):\n",
    "                print(f\"Discarded {len(data_records_all) - len(data_records_filtered)} records leaving {len(data_records_filtered)}.\")\n",
    "\n",
    "            if STRICT:\n",
    "                model_type = f\"{sheet_type}_strict\"\n",
    "            elif SEMI_STRICT:\n",
    "                model_type = f\"{sheet_type}_semistrict\"\n",
    "            else:\n",
    "                model_type = sheet_type\n",
    "\n",
    "            validator = validator_classes[model_type]\n",
    "            validated_rows = []\n",
    "            errors = [] # type is way too complicated to include :)\n",
    "            for row in data_records_filtered:\n",
    "                try:\n",
    "                    vr = validator(**row)\n",
    "                except ValidationError as e:\n",
    "                    if observatory_id == \"Bergen\":\n",
    "                        errors.append([(row[\"source_material_id\"], e.errors())])\n",
    "                    else:\n",
    "                        errors.append([(row[\"source_mat_id\"], e.errors())])\n",
    "                else:\n",
    "                    validated_rows.append(vr.model_dump())\n",
    "\n",
    "            if errors:\n",
    "                # errors is a list of lists where each inner list is a dict of row errors\n",
    "                # where each isof key = source_mat_id and values is list of dicts each of which\n",
    "                # is an error:\n",
    "                total_number_errors: int = sum([len(row[1]) for e in errors for row in e])\n",
    "                print(f\"Errors were found... {total_number_errors} in total\")\n",
    "                save_dir_errors: Path = Path(\"./validation_errors\")\n",
    "                #outfile_name_pk: str = f\"{observatory_id}_{sampling_strategy}_{model_type}_ERRORS.pickle\"\n",
    "                #out_path_pk: Path = os.path.join(save_dir, outfile_name_pk)\n",
    "                #with open(out_path_pk, \"wb\") as f:\n",
    "                #    pickle.dump(errors, f, pickle.HIGHEST_PROTOCOL)\n",
    "                outfile_name_log: Path = Path(f\"{observatory_id}_{sampling_strategy}_{model_type}_ERRORS.log\")\n",
    "                out_path_log: PurePath = PurePath(save_dir_errors, outfile_name_log)\n",
    "                #os.path.join(save_dir, outfile_name_log)                \n",
    "                with open(out_path_log, \"w\") as f:\n",
    "                    pprint(errors, f)\n",
    "            else:\n",
    "                assert len(validated_rows) == len(data_records_filtered), \"Not sure what happenned, but len(validated_rows) != len(data_filtered_records)\"\n",
    "                print(\"All records passed!\")\n",
    "            \n",
    "                #for record in validated_rows:\n",
    "                #    for field in record:\n",
    "                #        print(f\"Record {field} has value {record[field]} is type {type(record[field])}\")\n",
    "\n",
    "                if not STRICT and not SEMI_STRICT:\n",
    "                    save_dir_logsheets: Path = Path(\"./logsheets\")\n",
    "                    outfile_name: Path = Path(f\"{observatory_id}_{sampling_strategy}_{model_type}_validated.csv\")\n",
    "                    ndf = pd.DataFrame.from_records(validated_rows, index=\"source_mat_id\")\n",
    "                    ndf.to_csv(PurePath(save_dir_logsheets, outfile_name))\n",
    "                    print(f\"Written {os.path.join(save_dir_logsheets, outfile_name)}\")\n",
    "\n",
    "validator_classes = {\"sampling\": samplingModel,\n",
    "                     \"measured\": measuredModel,\n",
    "                     \"sampling_strict\": samplingModelStrict,\n",
    "                     \"sampling_semistrict\": samplingModelSemiStrict\n",
    "                    }\n",
    "\n",
    "# Get list of all URL links to sampling sheets\n",
    "# NB  you cant use a \"with\" closure here when reading the Pandas df\n",
    "governance_logsheets_validated_csv = \"./governance/logsheets_validated.csv\"\n",
    "df: pd.core.frame.DataFrame = pd.read_csv(governance_logsheets_validated_csv)\n",
    "water_column_sheet_addresses: list[tuple[str, str]] = df[[\"observatory_id\", \"water_column\"]].values.tolist()\n",
    "soft_sediment_sheet_addresses: list[tuple[str, str]]  = df[[\"observatory_id\", \"soft_sediment\"]].values.tolist()\n",
    "del df\n",
    "\n",
    "parse_sample_sheets(\"water_column\", \"sampling\", water_column_sheet_addresses)\n",
    "parse_sample_sheets(\"soft_sediment\", \"sampling\", soft_sediment_sheet_addresses)\n",
    "\n",
    "#There are not strict or semi-strict sheets for \"measured\"\n",
    "#parse_sample_sheets(\"water_column\", \"measured\", water_column_sheet_addresses)\n",
    "#parse_sample_sheets(\"soft_sediment\", \"measured\", soft_sediment_sheet_addresses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e07bc13-7b0b-4b94-84e3-3f2874f551ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mnote:\u001b[m In function \u001b[m\u001b[1m\"parse_sample_sheets\"\u001b[m:\u001b[m\n",
      "                        value: Union[str, float, None]\n",
      "\u001b[34mnote:\u001b[m By default the bodies of untyped functions are not checked, consider using --check-untyped-defs  [annotation-unchecked]\u001b[m\n",
      "                            value: Union[str, float, N\n",
      "\u001b[34mnote:\u001b[m By default the bodies of untyped functions are not checked, consider using --check-untyped-defs  [annotation-unchecked]\u001b[m\n",
      "                data_records_filtered: list[dict[str, \n",
      "\u001b[1m\u001b[31merror:\u001b[m Argument 1 to \u001b[m\u001b[1m\"filter\"\u001b[m has incompatible type \u001b[m\u001b[1m\"Callable[[Any], Any]\"\u001b[m; expected \u001b[m\u001b[1m\"Callable[[str], TypeGuard[dict[str, str]]]\"\u001b[m  \u001b[m\u001b[33m[arg-type]\u001b[m\n",
      "\u001b[1m\u001b[31mFound 1 error in 1 file (checked 1 source file)\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Type checking failed\n"
     ]
    }
   ],
   "source": [
    "%reload_ext mypy_ipython\n",
    "%mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab05ee-ca50-4ead-b2bf-e4d7fbc597d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
