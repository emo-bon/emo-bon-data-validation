{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fa567d-e682-4aff-bb5d-959c437212d6",
   "metadata": {},
   "source": [
    "### Pulls sheets from Github after QC curation by EMBRC, does \"lax\", \"strict\", and \"semi-strict\" validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae275a-eb87-4218-a735-93faee7ddee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Dict, List\n",
    "from urllib.request import HTTPError\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import ValidationError\n",
    "\n",
    "from validation_classes import (\n",
    "    samplingModelGithub,  # lax validator for EMO-BON Github repository\n",
    "    samplingModelGithubSemiStrict,  # semi-strict validator for EMO-BON Github repository\n",
    "    samplingModelGithubStrict,  # strict validator for EMO-BON Github repository\n",
    ")\n",
    "\n",
    "# Add project directory to path\n",
    "PROJECT_DIR = Path.cwd().parents[0]\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "sys.path.append(str(PROJECT_DIR / \"src\"))\n",
    "\n",
    "\n",
    "class SamplingStrategy(Enum):\n",
    "    WATER = \"water\"  # Originally water_column\n",
    "    SEDIMENT = \"sediment\"  # Originally soft_sediment\n",
    "\n",
    "\n",
    "class SheetType(Enum):\n",
    "    SAMPLING = \"sampling\"\n",
    "    MEASURED = \"measured\"\n",
    "\n",
    "\n",
    "# Not all observatories have \"transformed\" sheets on GH, but may have \"raw\"\n",
    "# Of course the types in the fields are different to difficult to validate\n",
    "# with a single validator - best just to ignore the raw sheets\n",
    "USE_RAW = False\n",
    "\n",
    "############################ CAUTION #############################################\n",
    "# As defined by Ioulia, dates corrected, NA's removed etc\n",
    "STRICT = False\n",
    "\n",
    "# As defined by Ioulia but not checking for mandatory fields\n",
    "# ints and str coerced to floats when possible\n",
    "SEMI_STRICT = False\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "def get_sheet_from_github(\n",
    "    observatory_id: SheetType,\n",
    "    sampling_strategy: SamplingStrategy,\n",
    "    sheet_type: str,\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Here we pull the \"sampling\" or \"measured\" sheets from Github. These are the curated\n",
    "    sheets downloaded by the Github actions and hopefully do not have the errors that\n",
    "    the CSV's pulled directly from Google Sheets had (e.g. the word \"blank\" magically\n",
    "    disappering from the \"replicate\" field.)\n",
    "\n",
    "    Github paths look like:\n",
    "    https://raw.githubusercontent.com/emo-bon/observatory-umf-crate/main/logsheets/transformed/sediment_measured.csv\n",
    "    https://raw.githubusercontent.com/emo-bon/observatory-bergen-crate/main/logsheets/raw/water_sampling.csv\n",
    "\n",
    "    The problem at 29-08-2024 is that the data are out of date.\n",
    "    \"\"\"\n",
    "\n",
    "    prefix = \"https://raw.githubusercontent.com/emo-bon\"\n",
    "    obs_name = f\"observatory-{observatory_id}-crate\"\n",
    "    inter_path = \"main/logsheets\"\n",
    "    dir_path = \"transformed\"\n",
    "    sheet_name = f\"{sampling_strategy}_{sheet_type}.csv\"\n",
    "\n",
    "    print(f\"Processing {observatory_id}... {sheet_name}\")\n",
    "    github_addr = os.path.join(prefix, obs_name, inter_path, dir_path, sheet_name)\n",
    "    try:\n",
    "        df = pd.read_csv(github_addr)\n",
    "    except HTTPError:\n",
    "        # Some observatories don't yet have transformed sheets\n",
    "        if USE_RAW:\n",
    "            # Try for the raw sheets\n",
    "            print(\"Unable to find 'transformed' sheet, reading the 'raw' sheet\")\n",
    "            dir_path = \"raw\"\n",
    "            github_addr = os.path.join(\n",
    "                prefix, obs_name, inter_path, dir_path, sheet_name\n",
    "            )\n",
    "            try:\n",
    "                df = pd.read_csv(github_addr)\n",
    "            except HTTPError as err:\n",
    "                raise ValueError(\"Unable to find transformed or raw sheet\") from err\n",
    "        else:\n",
    "            print(\n",
    "                f\"Observatory {observatory_id} does not have a transformed {sheet_name} on GH\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_on_source_mat_id(d):\n",
    "    # Bergen has it as source_material_id on Google and Github\n",
    "    try:\n",
    "        value = d[\"source_mat_id\"]\n",
    "    except KeyError as err:  # noqa: F841\n",
    "        try:\n",
    "            value = d[\"source_material_id\"]\n",
    "        except KeyError as err:\n",
    "            raise ValueError(\"Cannot find source_mat_id field\") from err\n",
    "    if (  # noqa: SIM103\n",
    "        not value\n",
    "        or isinstance(value, float)\n",
    "        or len(value.split(\"_\") < 6)\n",
    "        or value == \"EMOBON_VB_Wa_230509_um_\"\n",
    "    ):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def parse_sample_sheets(\n",
    "    sampling_strategy: str,\n",
    "    sheet_type: str,\n",
    "    addresses: pd.core.frame.DataFrame,\n",
    ") -> None:\n",
    "    for observatory in addresses:\n",
    "        observatory_id, sheet_link = observatory\n",
    "        # print(f\"ObSservatory_id {observatory_id} sheet_link {sheet_link}\")\n",
    "        if not isinstance(sheet_link, str):\n",
    "            # print(f\"This is the sheet_link type {type(sheet_link)}\")\n",
    "            if isinstance(sheet_link, float):\n",
    "                # Only OOB doesnt do water_column\n",
    "                # But most do not do soft-sediments\n",
    "                if math.isnan(sheet_link):\n",
    "                    print(\n",
    "                        f\"Observatory {observatory_id} does not have a {sampling_strategy} sampling strategy.\"\n",
    "                    )\n",
    "                    continue\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Unknown value '{sheet_link}' in {sampling_strategy} cell of {observatory_id}\"\n",
    "                )\n",
    "        else:\n",
    "            if observatory_id == \"Plenzia\":\n",
    "                continue  # Sheets not publically available\n",
    "\n",
    "            ################ CAUTION ##################\n",
    "            # if not observatory_id in [\"AAOT\"]: continue\n",
    "\n",
    "            # UMF soft_sed has two source_mat_ids\n",
    "            if sampling_strategy == \"sediment\" and observatory_id == \"UMF\":\n",
    "                continue\n",
    "\n",
    "            df = get_sheet_from_github(observatory_id, sampling_strategy, sheet_type)\n",
    "            if df is None:\n",
    "                continue\n",
    "            data_records_all = df.to_dict(orient=\"records\")\n",
    "\n",
    "            # Many sheets have partially filled rows\n",
    "            # The source_mat_id is manually curated and the PRIMARY_KEY\n",
    "            # Therefore filter records on source_mat_id\n",
    "\n",
    "            data_records_filtered = list(\n",
    "                filter(filter_on_source_mat_id, data_records_all)\n",
    "            )\n",
    "\n",
    "            if len(data_records_all) > len(data_records_filtered):\n",
    "                print(\n",
    "                    f\"Discarded {len(data_records_all) - len(data_records_filtered)} records leaving {len(data_records_filtered)}.\"\n",
    "                )\n",
    "\n",
    "            ################ CAUTION ##############\n",
    "            # continue\n",
    "\n",
    "            if STRICT:\n",
    "                model_type = f\"{sheet_type}_github_strict\"\n",
    "            elif SEMI_STRICT:\n",
    "                model_type = f\"{sheet_type}_github_semistrict\"\n",
    "            else:\n",
    "                model_type = f\"{sheet_type}_github\"\n",
    "\n",
    "            validator = validator_classes[model_type]\n",
    "            # print(f\"Using {validator} from {model_type}\")\n",
    "\n",
    "            # validated_rows = [validator(**row).model_dump() for row in data_records_filtered]\n",
    "            validated_rows = []\n",
    "            errors: List[\n",
    "                List[str : List[Dict]]\n",
    "            ] = []  # where each error is the inner Dict\n",
    "            for row in data_records_filtered:\n",
    "                try:\n",
    "                    vr = validator(**row)\n",
    "                except ValidationError as e:\n",
    "                    if observatory_id == \"Bergen\":\n",
    "                        errors.append([(row[\"source_material_id\"], e.errors())])\n",
    "                    else:\n",
    "                        errors.append([(row[\"source_mat_id\"], e.errors())])\n",
    "                else:\n",
    "                    validated_rows.append(vr.model_dump())\n",
    "\n",
    "            if errors:\n",
    "                # errors is a list of lists where each inner list is a dict of row errors\n",
    "                # where each isof key = source_mat_id and values is list of dicts each of which\n",
    "                # is an error:\n",
    "                # List[List[str:List[Dict]]]\n",
    "                total_number_errors = sum([len(row[1]) for e in errors for row in e])\n",
    "                print(f\"Errors were found... {total_number_errors} in total\")\n",
    "                save_dir = PROJECT_DIR / \"logs\" / \"validation_errors_github\"\n",
    "                outfile_name_log = (\n",
    "                    f\"{observatory_id}_{sampling_strategy}_{model_type}_ERRORS.log\"\n",
    "                )\n",
    "                out_path_log = save_dir / outfile_name_log\n",
    "                with open(out_path_log, \"w\") as f:\n",
    "                    pprint(errors, f)\n",
    "            else:\n",
    "                if len(validated_rows) != len(data_records_filtered):\n",
    "                    raise RuntimeError(\n",
    "                        \"Error: len(validated_rows) != len(data_filtered_records)\"\n",
    "                    )\n",
    "                print(\"All records passed!\")\n",
    "\n",
    "                # for record in validated_rows:\n",
    "                #    for field in record:\n",
    "                #        print(f\"Record {field} has value {record[field]} is type {type(record[field])}\")\n",
    "\n",
    "                if not STRICT and not SEMI_STRICT:\n",
    "                    save_dir = PROJECT_DIR / \"validated-data\" / \"logsheets_github\"\n",
    "                    outfile_name = f\"{observatory_id}_{sampling_strategy}_{model_type}_validated.csv\"\n",
    "                    ndf = pd.DataFrame.from_records(\n",
    "                        validated_rows, index=\"source_mat_id\"\n",
    "                    )\n",
    "                    ndf.to_csv(save_dir / outfile_name)\n",
    "                    print(f\"Written {save_dir / outfile_name}\")\n",
    "\n",
    "\n",
    "validator_classes = {\n",
    "    \"sampling_github\": samplingModelGithub,\n",
    "    \"sampling_github_strict\": samplingModelGithubStrict,\n",
    "    \"sampling_github_semistrict\": samplingModelGithubSemiStrict,\n",
    "}\n",
    "\n",
    "# Get list of all URL links to sampling sheets\n",
    "# NB  you cant use a \"with\" closure here when reading the Pandas df\n",
    "validated_csv = (\n",
    "    PROJECT_DIR / \"validated-data\" / \"governance\" / \"logsheets_validated.csv\"\n",
    ")\n",
    "df = pd.read_csv(validated_csv)\n",
    "water_column_sheet_addresses = df[[\"observatory_id\", \"water_column\"]].values.tolist()\n",
    "soft_sediment_sheet_addresses = df[[\"observatory_id\", \"soft_sediment\"]].values.tolist()\n",
    "del df\n",
    "\n",
    "parse_sample_sheets(\"water\", \"sampling\", water_column_sheet_addresses)\n",
    "parse_sample_sheets(\"sediment\", \"sampling\", soft_sediment_sheet_addresses)\n",
    "# parse_sample_sheets(\"water\", \"measured\", water_column_sheet_addresses)\n",
    "# parse_sample_sheets(\"sediment\", \"measured\", soft_sediment_sheet_addresses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
